{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slazur83/Tableau/blob/main/MusicTracks_exporter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Zo_gO9OWB_e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import csv\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_duplicate_rows(df):\n",
        "    duplicates = df[df.duplicated()]\n",
        "    if duplicates.empty:\n",
        "        return \"No duplicates found in the data.\"\n",
        "    else:\n",
        "        return f\"Found {len(duplicates)} duplicate rows.\"\n",
        "\n",
        "\n",
        "def check_duplicate_rows_without_column(df, column_to_exclude):\n",
        "    df_copy = df.drop(columns=column_to_exclude)\n",
        "    duplicates = df_copy[df_copy.duplicated()]\n",
        "\n",
        "    if duplicates.empty:\n",
        "        num_removed=0\n",
        "        return f\"No duplicates found in the data, excluding the specified column {column_to_exclude}).\", df\n",
        "    else:\n",
        "        print(f\"Found {len(duplicates)} duplicate rows (excluding the specified column {column_to_exclude}).\")\n",
        "        question = input(\"Do you want to delete replicated rows? Y/N\\n\")\n",
        "        if question.upper() == \"Y\":\n",
        "            df_cleaned = df[~df_copy.duplicated(keep='first')]\n",
        "            return df_cleaned\n",
        "        else:\n",
        "            return \"No rows have been removed\"\n",
        "\n",
        "\n",
        "def format_date(date_str):\n",
        "    # Function to format date strings with or without seconds\n",
        "    if date_str == 'N/A':\n",
        "        return 'N/A'\n",
        "\n",
        "    try:\n",
        "        # Try parsing with seconds first\n",
        "        return datetime.strptime(date_str, '%d %b %Y, %H:%M:%S').strftime('%Y-%m-%d %H:%M')\n",
        "    except ValueError:\n",
        "        # If parsing fails, try without seconds\n",
        "        try:\n",
        "            return datetime.strptime(date_str, '%d %b %Y, %H:%M').strftime('%Y-%m-%d %H:%M')\n",
        "        except ValueError:\n",
        "            # Handle cases where the date string might not match expected formats\n",
        "            print(f\"Date format error for: {date_str}\")\n",
        "            return 'Invalid Date Format'\n",
        "\n",
        "\n",
        "def find_highest_version_file(directory, base_filename):\n",
        "    # Pattern to match files like 'lastfm_tracks.csv'\n",
        "    pattern = re.compile(rf'{re.escape(base_filename)}\\.(csv)')\n",
        "    highest_version = -1\n",
        "    selected_file = None\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        match = pattern.match(filename)\n",
        "        if match:\n",
        "            selected_file = filename\n",
        "\n",
        "    return selected_file\n",
        "\n",
        "\n",
        "def convert_to_datetime(date_str):\n",
        "    # Handle date parsing with different formats\n",
        "    try:\n",
        "        return pd.to_datetime(date_str, format='%Y-%m-%d %H:%M', errors='coerce')\n",
        "    except ValueError:\n",
        "        print(f\"Date format error for: {date_str}\")\n",
        "        return pd.NaT\n",
        "\n",
        "\n",
        "def extract_artist(subtitles):\n",
        "    if isinstance(subtitles, list) and len(subtitles) > 0:\n",
        "        return subtitles[0].get('name', '').split(' - ')[0]\n",
        "    return ''\n",
        "\n",
        "\n",
        "def extract_song_title(title):\n",
        "    if title.startswith(\"Obejrzano: \"):\n",
        "        return title.replace(\"Obejrzano: \", \"\")\n",
        "    return title"
      ],
      "metadata": {
        "id": "WtVDpCVm1Lay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "config_file_path = \"/content/drive/MyDrive/Skrypty/config.json\"\n",
        "\n",
        "with open(config_file_path, 'r') as config_file:\n",
        "    config = json.load(config_file)"
      ],
      "metadata": {
        "id": "XnWTmkvdtw-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYt3e2Mrej3L"
      },
      "source": [
        "# **LastFM**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API credentials\n",
        "last_fm_api_key = config['last_fm_api_key']\n",
        "user_name = 'slazur83'\n",
        "\n",
        "# Base API URL\n",
        "base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
        "params = {\n",
        "    'method': 'user.getrecenttracks',\n",
        "    'user': user_name,\n",
        "    'api_key': last_fm_api_key,\n",
        "    'format': 'json',\n",
        "    'limit': 200,\n",
        "    'page': 1\n",
        "}\n",
        "\n",
        "# CSV file setup\n",
        "base_filename = \"lastfm_tracks.csv\"\n",
        "directory = '.'  # Current directory\n",
        "drive_folder = '/content/drive/MyDrive/Dane z aplikacji/LastFM/'\n",
        "\n",
        "# Find the file with the fixed name\n",
        "csv_file = find_highest_version_file(directory, base_filename)\n",
        "\n",
        "if csv_file is None:\n",
        "    # If no file found, use base_filename directly\n",
        "    csv_file = base_filename\n",
        "\n",
        "# Open CSV file for writing\n",
        "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['artist', 'track', 'album', 'playback_date'])  # Header row\n",
        "\n",
        "    while True:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        tracks = data.get('recenttracks', {}).get('track', [])\n",
        "        if not tracks:\n",
        "            break\n",
        "\n",
        "        for track in tracks:\n",
        "            artist = track.get('artist', {}).get('#text', 'N/A')\n",
        "            track_name = track.get('name', 'N/A')\n",
        "            album = track.get('album', {}).get('#text', 'N/A')\n",
        "            playback_date = format_date(track.get('date', {}).get('#text', 'N/A'))\n",
        "\n",
        "            writer.writerow([artist, track_name, album, playback_date])\n",
        "\n",
        "        params['page'] += 1\n",
        "\n",
        "print(f\"Data written to {csv_file}\")\n",
        "\n",
        "# Move the file to the Google Drive folder\n",
        "shutil.copy(csv_file, drive_folder)\n",
        "print(f\"The file {csv_file} has been moved to {drive_folder}.\")\n",
        "\n",
        "# Read the CSV file into a dataframe\n",
        "df_lastfm = pd.read_csv(drive_folder + csv_file, header=0)  # Use header=0 to skip the header row\n",
        "df_lastfm.columns = ['Artist', 'Track', 'Album', 'Date']  # Rename columns\n",
        "\n",
        "def convert_to_datetime(date_str):\n",
        "    # Handle date parsing with different formats\n",
        "    try:\n",
        "        return pd.to_datetime(date_str, format='%Y-%m-%d %H:%M', errors='coerce')\n",
        "    except ValueError:\n",
        "        print(f\"Date format error for: {date_str}\")\n",
        "        return pd.NaT\n",
        "\n",
        "# Convert the Date column to datetime format\n",
        "df_lastfm['Date'] = df_lastfm['Date'].apply(convert_to_datetime)\n",
        "\n",
        "# Convert the Date column to the desired format\n",
        "df_lastfm['Date'] = df_lastfm['Date'].dt.strftime('%Y-%m-%d %H:%M')\n",
        "df_lastfm['Source'] = 'LastFM'\n",
        "df_lastfm['Account'] = 'slazur83'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H502C8AD3C6W",
        "outputId": "5fe65706-3036-4837-f391-a074ce01e25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data written to lastfm_tracks.csv\n",
            "The file lastfm_tracks.csv has been moved to /content/drive/MyDrive/Dane z aplikacji/LastFM/.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YouTube Music**"
      ],
      "metadata": {
        "id": "GN45KgJ9Dc-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the source file\n",
        "source_file = '/content/drive/MyDrive/Dane z aplikacji/Google/riwanna85/YouTube i YouTube Music/historia/historia oglaÌ¨dania.json'\n",
        "\n",
        "# Load the JSON file into a DataFrame\n",
        "df_ytmusic = pd.read_json(source_file, encoding='utf-8')\n",
        "\n",
        "# Filter rows for YouTube Music\n",
        "df_ytmusic = df_ytmusic[df_ytmusic['header'] == 'YouTube Music'].copy()\n",
        "\n",
        "# Extract artist, track, and date information\n",
        "df_ytmusic['Artist'] = df_ytmusic['subtitles'].apply(extract_artist)\n",
        "df_ytmusic['Track'] = df_ytmusic['title'].apply(extract_song_title)\n",
        "df_ytmusic['Date'] = pd.to_datetime(df_ytmusic['time'], format='ISO8601').dt.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "# Add additional columns\n",
        "df_ytmusic['Source'] = 'YouTube Music'\n",
        "df_ytmusic['Account'] = 'riwanna85'\n",
        "df_ytmusic['Duration'] = 'N/A'\n",
        "\n",
        "# Reorder columns\n",
        "df_ytmusic = df_ytmusic[['Artist', 'Track', 'Date', 'Duration', 'Source', 'Account']]"
      ],
      "metadata": {
        "id": "ORM0sMM_DcLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqLYlxpjTaKw"
      },
      "source": [
        "# **Spotify**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_spotify_data(file_pattern, account_email):\n",
        "    # File path to the JSON files\n",
        "    file_list = glob.glob(file_pattern)\n",
        "    df_list = []\n",
        "\n",
        "    for filename in file_list:\n",
        "        with open(filename, encoding='utf-8') as inputfile:\n",
        "            df = pd.read_json(inputfile)\n",
        "            df_list.append(df)\n",
        "\n",
        "    df_combined = pd.concat(df_list, ignore_index=True)\n",
        "    df_combined['Account'] = account_email\n",
        "\n",
        "    print(f'There are {len(df_combined)} rows in a DataFrame for {account_email}.')\n",
        "    check_duplicate_rows(df=df_combined)\n",
        "    return df_combined\n",
        "\n",
        "# Load data for both accounts\n",
        "df1 = load_spotify_data('/content/drive/MyDrive/Dane z aplikacji/Spotify/slazur83@gmail.com/MyData/StreamingHistory*.json', 'slazur83')\n",
        "df2 = load_spotify_data('/content/drive/MyDrive/Dane z aplikacji/Spotify/zethar182@gmail.com/MyData/StreamingHistory*.json', 'zethar182')\n",
        "\n",
        "# Combine data from both accounts\n",
        "df_spotify = pd.concat([df1, df2], ignore_index=True)\n",
        "df_spotify['Source'] = 'Spotify'\n",
        "\n",
        "print(f'There are {len(df_spotify)} rows in the combined DataFrame.')\n",
        "\n",
        "# Remove duplicate rows, excluding the 'Account' column\n",
        "df_spotify = df_spotify.drop_duplicates(subset=df_spotify.columns.difference(['Account']))\n",
        "\n",
        "# Rename columns in the dataframe (using a copy to avoid SettingWithCopyWarning)\n",
        "df_spotify = df_spotify.rename(columns={'endTime': 'Date', 'artistName': 'Artist', 'trackName': 'Track', 'msPlayed': 'Duration'})\n",
        "\n",
        "# Reorder columns in the dataframe\n",
        "df_spotify = df_spotify[['Artist', 'Track', 'Date', 'Duration', 'Source', 'Account']]\n",
        "\n",
        "print(f'There are {len(df_spotify)} rows in the final DataFrame after removing duplicates.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QPutDy0IGH6",
        "outputId": "b362031c-bfcb-4f46-d208-f876c916ffe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 20571 rows in a DataFrame for slazur83.\n",
            "There are 9692 rows in a DataFrame for zethar182.\n",
            "There are 30263 rows in the combined DataFrame.\n",
            "There are 20646 rows in the final DataFrame after removing duplicates.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8veMxiBg5QJ"
      },
      "source": [
        "# **Deezer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xH9JpEB3SVt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File path to the Excel file\n",
        "deezer_file = '/content/drive/MyDrive/Dane z aplikacji/Deezer/4519420622.xlsx'\n",
        "\n",
        "# Read the specified sheet from the Excel file into a DataFrame\n",
        "df_deezer = pd.read_excel(deezer_file, sheet_name=\"10_listeningHistory\")\n",
        "\n",
        "# Rename columns in the DataFrame\n",
        "df_deezer = df_deezer.rename(columns={\n",
        "    'Song Title': 'Track',\n",
        "    'Album Title': 'Album',\n",
        "    'Listening Time': 'Duration',\n",
        "    'Platform Name': 'Platform'\n",
        "})\n",
        "\n",
        "# Delete the 'ISRC' column from the DataFrame\n",
        "df_deezer = df_deezer.drop(columns=['ISRC'])\n",
        "\n",
        "# Add new columns to the DataFrame\n",
        "df_deezer['Source'] = 'Deezer'\n",
        "df_deezer['Account'] = 'slazur83'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final DataFrame**"
      ],
      "metadata": {
        "id": "WEZDcOfTLZD7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWG1LUHv6ITr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed32b9f9-05c8-4b89-da2a-3a01308d8401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All data is merged\n",
            "No null values found in the Date column.\n",
            "Spotify: 2022-10-26 18:09 to 2023-10-09 19:53\n",
            "Deezer: 2021-08-06 17:11:48 to 2023-03-05 19:16:53\n",
            "LastFM: 2021-12-23 07:36 to 2024-08-16 14:51\n",
            "YouTube Music: 2024-03-10 18:13 to 2024-08-05 16:20\n"
          ]
        }
      ],
      "source": [
        "# Concatenate the DataFrames and verify successful merge\n",
        "merged = pd.concat([df_spotify, df_ytmusic, df_lastfm, df_deezer], ignore_index=True)\n",
        "total_length = len(df_spotify) + len(df_ytmusic) + len(df_lastfm) + len(df_deezer)\n",
        "\n",
        "assert len(merged) == total_length, \"Not all data is merged\"\n",
        "print('All data is merged')\n",
        "\n",
        "# Handle null values in the 'Date' column\n",
        "nulls = merged['Date'].isna().sum()\n",
        "\n",
        "if nulls > 0:\n",
        "    if nulls < 15:\n",
        "        merged.dropna(subset=['Date'], inplace=True)\n",
        "        print(f'Dropped {nulls} rows with missing Date values.')\n",
        "    else:\n",
        "        raise ValueError(f'There are {nulls} null values in the Date column that need attention.')\n",
        "else:\n",
        "    print('No null values found in the Date column.')\n",
        "\n",
        "# Reorder columns and format the 'Date' column\n",
        "columns_order = ['Date', 'Artist', 'Track', 'Album', 'Duration', 'Source', 'Account', 'Platform', 'Platform Model', 'IP Address']\n",
        "merged = merged[columns_order]\n",
        "\n",
        "# Convert 'Date' column to datetime format\n",
        "merged['Date'] = pd.to_datetime(merged['Date'])\n",
        "merged.sort_values(by='Date', inplace=True)\n",
        "\n",
        "# Print the date range for each dataframe\n",
        "print(f\"Spotify: {df_spotify['Date'].min()} to {df_spotify['Date'].max()}\")\n",
        "print(f\"Deezer: {df_deezer['Date'].min()} to {df_deezer['Date'].max()}\")\n",
        "print(f\"LastFM: {df_lastfm['Date'].min()} to {df_lastfm['Date'].max()}\")\n",
        "print(f\"YouTube Music: {df_ytmusic['Date'].min()} to {df_ytmusic['Date'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the DataFrame to CSV\n",
        "output_path = '/content/drive/MyDrive/Skrypty/Tableau/Outputs/music_tracks.csv'\n",
        "merged.to_csv(output_path, index=False)\n",
        "print(f'Data successfully exported to {output_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxsIQgr6V4ZM",
        "outputId": "ed5a4fdc-1d6a-4472-96dc-a498d392bbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully exported to /content/drive/MyDrive/Skrypty/Tableau/Outputs/music_tracks.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Nxr7fSxPw5_9luzBYxemvGg8v40m-82q",
      "authorship_tag": "ABX9TyMKqTM6ShwOwcBdHj6LX+U/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}