{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OfrG9xX34KXc6L12nplbNUam2peFpgjk",
      "authorship_tag": "ABX9TyN3v+QIZW0WbAj41mAq8KMo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Moje projekty/Tableau/Source data\"\n",
        "EXPORT_DIR = \"/content/drive/MyDrive/Moje projekty/Garmin Connect/Garmin exports\"\n",
        "\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "    print(f\"Created output directory → {OUTPUT_DIR}\")\n",
        "\n",
        "\n",
        "if not os.path.exists(EXPORT_DIR):\n",
        "    os.makedirs(EXPORT_DIR)\n",
        "    print(f\"Created export directory → {EXPORT_DIR}\")\n",
        "\n",
        "\n",
        "def get_season(d):\n",
        "    m, day = d.month, d.day\n",
        "    if (m == 12 and day >= 21) or m in [1,2] or (m == 3 and day < 21):\n",
        "        return 'Winter'\n",
        "    elif (m == 3 and day >= 21) or m in [4,5] or (m == 6 and day < 21):\n",
        "        return 'Spring'\n",
        "    elif (m == 6 and day >= 21) or m in [7,8] or (m == 9 and day < 23):\n",
        "        return 'Summer'\n",
        "    elif (m == 9 and day >= 23) or m in [10,11] or (m == 12 and day < 21):\n",
        "        return 'Autumn'\n",
        "    return 'Unknown'\n",
        "\n",
        "\n",
        "raw_files = [f for f in glob.glob(os.path.join(EXPORT_DIR, \"*.csv\"))\n",
        "             if \"enriched\" not in os.path.basename(f)]\n",
        "\n",
        "\n",
        "if raw_files:\n",
        "    print(\"\\n=== RAW FILES FOUND — PROCESSING ===\")\n",
        "else:\n",
        "    print(\"\\n=== NO RAW FILES — SKIPPING ===\")\n",
        "\n",
        "\n",
        "for f in raw_files:\n",
        "    name = os.path.basename(f)\n",
        "    print(f\"\\nProcessing RAW file → {name}\")\n",
        "\n",
        "    df = pd.read_csv(f)\n",
        "    if \"Date\" not in df.columns:\n",
        "        raise ValueError(f\"RAW file {f} must contain 'Date'\")\n",
        "    df = df.rename(columns={\"Date\": \"New_date\"})\n",
        "\n",
        "    df[\"New_date\"] = pd.to_datetime(df[\"New_date\"], errors=\"coerce\")\n",
        "    df = df[df[\"New_date\"].notna()]\n",
        "    df = df[df[\"Steps\"] > 0]\n",
        "    df = df.sort_values(\"New_date\").drop_duplicates(\"New_date\", keep=\"last\")\n",
        "\n",
        "    df[\"Month\"] = df[\"New_date\"].dt.month_name()\n",
        "    df[\"Weekday\"] = df[\"New_date\"].dt.day_name()\n",
        "    df[\"Season\"] = df[\"New_date\"].apply(get_season)\n",
        "\n",
        "    min_d, max_d = df[\"New_date\"].min(), df[\"New_date\"].max()\n",
        "    full = pd.date_range(min_d, max_d, freq=\"D\")\n",
        "    missing = full.difference(df[\"New_date\"])\n",
        "    if len(missing) > 0:\n",
        "        print(f\"Missing {len(missing)} days — filling with NaN\")\n",
        "        missing_df = pd.DataFrame({\n",
        "            \"New_date\": missing,\n",
        "            \"Steps\": [float(\"nan\")] * len(missing),\n",
        "        })\n",
        "        df = pd.concat([df, missing_df])\n",
        "\n",
        "    df = df.sort_values(\"New_date\").reset_index(drop=True)\n",
        "    min_date, max_date = df[\"New_date\"].min(), df[\"New_date\"].max()\n",
        "\n",
        "    if min_date.month == 1 and min_date.day == 1 and max_date.month == 12 and max_date.day == 31:\n",
        "      enriched_name = f\"steps_export_{min_date.year}_enriched.csv\"\n",
        "    else:\n",
        "      enriched_name = f\"steps_export_{min_date.strftime('%Y%m%d')}_{max_date.strftime('%Y%m%d')}_enriched.csv\"\n",
        "\n",
        "    enriched_path = os.path.join(EXPORT_DIR, enriched_name)\n",
        "    df.to_csv(enriched_path, index=False)\n",
        "    print(f\"Saved enriched file → {enriched_name}\")\n",
        "    os.remove(f)\n",
        "    print(f\"Removed RAW file → {name}\")\n",
        "\n",
        "enriched_files = [f for f in glob.glob(os.path.join(EXPORT_DIR, \"*_enriched.csv\"))]\n",
        "\n",
        "print(\"\\n=== CLEANING enriched FILES ===\")\n",
        "\n",
        "dfs = []\n",
        "for f in enriched_files:\n",
        "    name = os.path.basename(f)\n",
        "    df = pd.read_csv(f)\n",
        "    df[\"New_date\"] = pd.to_datetime(df[\"New_date\"])\n",
        "\n",
        "    print(\"\\n-------------------------------------------\")\n",
        "    print(\"FILE:\", name)\n",
        "    print(\"Rows:\", len(df))\n",
        "    print(\"Unique dates:\", df[\"New_date\"].nunique())\n",
        "\n",
        "    duplicates = df[df.duplicated(\"New_date\", keep=False)]\n",
        "    if len(duplicates) > 0:\n",
        "        print(f\"!!! WARNING: {len(duplicates)} duplicates\")\n",
        "        df = df.sort_values(\"New_date\").drop_duplicates(\"New_date\", keep=\"last\")\n",
        "        df.to_csv(f, index=False)\n",
        "        print(f\"Duplicates removed → overwritten {name}\")\n",
        "    else:\n",
        "        print(\"No duplicates inside file.\")\n",
        "\n",
        "    min_date, max_date = df[\"New_date\"].min(), df[\"New_date\"].max()\n",
        "    print(\"Date range:\", min_date.date(), \"→\", max_date.date())\n",
        "\n",
        "    full_range = pd.date_range(min_date, max_date, freq=\"D\")\n",
        "    missing = full_range.difference(df[\"New_date\"])\n",
        "    if len(missing) == 0:\n",
        "        print(\"Missing dates: NONE\")\n",
        "    else:\n",
        "        print(f\"Missing dates ({len(missing)}):\")\n",
        "        for d in missing:\n",
        "            print(\" -\", d.date())\n",
        "        missing_df = pd.DataFrame({\n",
        "            \"New_date\": missing,\n",
        "            \"Steps\": [float(\"nan\")] * len(missing),\n",
        "        })\n",
        "        df = pd.concat([df, missing_df])\n",
        "\n",
        "    dfs.append(df)\n",
        "\n",
        "print(\"\\n=== REMOVING narrower enriched files ===\")\n",
        "\n",
        "range_files = []\n",
        "for f in enriched_files:\n",
        "    base = os.path.basename(f)\n",
        "\n",
        "    if base.startswith(\"steps_export_\") and base.endswith(\"_enriched.csv\"):\n",
        "        try:\n",
        "            part = base.replace(\"steps_export_\", \"\").replace(\"_enriched.csv\", \"\")\n",
        "            start_s, end_s = part.split(\"_\")\n",
        "\n",
        "            start_d = datetime.strptime(start_s, \"%Y%m%d\")\n",
        "            end_d = datetime.strptime(end_s, \"%Y%m%d\")\n",
        "\n",
        "            range_files.append((f, start_d, end_d))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "from collections import defaultdict\n",
        "groups = defaultdict(list)\n",
        "for f, start_d, end_d in range_files:\n",
        "    groups[start_d].append((f, end_d))\n",
        "\n",
        "for start_d, file_list in groups.items():\n",
        "    if len(file_list) <= 1:\n",
        "        continue\n",
        "\n",
        "    file_list_sorted = sorted(file_list, key=lambda x: x[1], reverse=True)\n",
        "    keep_file, keep_end = file_list_sorted[0]\n",
        "\n",
        "    print(f\"\\nKEEP: {os.path.basename(keep_file)}\")\n",
        "\n",
        "    for f_rm, end_rm in file_list_sorted[1:]:\n",
        "        print(f\"REMOVE: {os.path.basename(f_rm)}\")\n",
        "        os.remove(f_rm)\n",
        "\n",
        "enriched_files = [f for f in glob.glob(os.path.join(EXPORT_DIR, \"*_enriched.csv\"))]\n",
        "\n",
        "print(\"\\n=== MERGING ALL enriched FILES ===\")\n",
        "\n",
        "final = pd.concat(dfs, ignore_index=True)\n",
        "final = final.sort_values(\"New_date\").drop_duplicates(\"New_date\", keep=\"last\").reset_index(drop=True)\n",
        "final[\"Month\"] = final[\"New_date\"].dt.month_name()\n",
        "final[\"Weekday\"] = final[\"New_date\"].dt.day_name()\n",
        "final[\"Season\"] = final[\"New_date\"].apply(get_season)\n",
        "\n",
        "if \"Unnamed: 0\" in final.columns:\n",
        "    final = final.drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "final.insert(0, \"ID\", range(1, len(final) + 1))\n",
        "\n",
        "today_str = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "final_path = os.path.join(OUTPUT_DIR, \"steps_all_years_merged.csv\")\n",
        "final.to_csv(final_path, index=False)\n",
        "\n",
        "start_date = final[\"New_date\"].min().strftime(\"%Y-%m-%d\")\n",
        "end_date = final[\"New_date\"].max().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "print(\"FINAL DATASET CREATED\")\n",
        "print(\"Date range:\", start_date, \"→\", end_date)\n",
        "print(\"Total days:\", len(final))\n",
        "print(\"Total steps:\", final[\"Steps\"].sum())\n",
        "\n",
        "print(\"\\nAverage steps per year:\")\n",
        "final[\"Year\"] = final[\"New_date\"].dt.year\n",
        "for yr, grp in final.groupby(\"Year\"):\n",
        "    print(f\"{yr}: {int(grp['Steps'].mean()) if not grp['Steps'].isna().all() else 'NaN'}\")\n",
        "\n",
        "print(\"\\nSaved to:\")\n",
        "print(final_path)\n"
      ],
      "metadata": {
        "id": "_nDqjIlbWvr0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}