{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slazur83/Tableau/blob/main/MusicTracks_exporter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import logging\n",
        "import time\n",
        "import re\n",
        "import csv\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "wgqY8HzEq6y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piICG08Xz8Ro"
      },
      "outputs": [],
      "source": [
        "drive_path = '/content/drive/MyDrive'\n",
        "\n",
        "if not os.path.exists(drive_path):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "config_file_path = os.path.join(drive_path, \"Skrypty\", \"config.json\")\n",
        "\n",
        "try:\n",
        "    with open(config_file_path, 'r') as config_file:\n",
        "        config = json.load(config_file)\n",
        "        print(\"Configuration file loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Configuration file not found at {config_file_path}.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(\"Error: Failed to parse the configuration file. Please check the file's content.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4ouSJ5a_QAd"
      },
      "outputs": [],
      "source": [
        "SPECIAL_CHARACTER_MAPPING = {\n",
        "    \"Chylinska\": \"Chylińska\",\n",
        "    \"Toure\": \"Touré\",\n",
        "    \"Ashford Simpson\": \"Ashford & Simpson\",\n",
        "    \"Anderson Paak\": \"Anderson .Paak\",\n",
        "    \"Anderson .paak\": \"Anderson .Paak\",\n",
        "    \"Axwell Ingrosso\": \"Axwell /\\ Ingrosso\",\n",
        "    \"Zodiac Mindwarp The Love Reaction\": \"Zodiac Mindwarp & The Love Reaction\",\n",
        "    \"Durand Jones The Indications\" : \"Durand Jones & The Indications\"\n",
        "}\n",
        "\n",
        "def standardize_artist_and_track(artist, track):\n",
        "\n",
        "    if not pd.notna(artist) or not pd.notna(track):\n",
        "        return artist, track\n",
        "\n",
        "    if artist:\n",
        "        artist = ' '.join(artist.split())\n",
        "        artist = artist.replace('St ', 'St. ').replace(' And ', ' & ').replace(' and ', ' & ').replace(' AND ', ' & ')\n",
        "        artist = re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', artist)\n",
        "\n",
        "        for original, replacement in SPECIAL_CHARACTER_MAPPING.items():\n",
        "            artist = artist.replace(original, replacement)\n",
        "\n",
        "        if artist.lower().endswith(' vevo'):\n",
        "            artist = artist[:-5].strip()\n",
        "\n",
        "        words = artist.split()\n",
        "        artist = ' '.join(word.capitalize() if word.lower() != '&' else '&' for word in words)\n",
        "\n",
        "    if track:\n",
        "        track = ' '.join(track.strip().title().split())\n",
        "\n",
        "    feat_match = re.search(r'\\(feat\\. (.*?)\\)', track, re.IGNORECASE)\n",
        "    if feat_match:\n",
        "        featured_artist = feat_match.group(1).strip()\n",
        "        if featured_artist.lower() not in artist.lower():\n",
        "            artist = f\"{artist}, {featured_artist}\"\n",
        "        track = re.sub(r'\\(feat\\. .*?\\)', '', track, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    return artist, track\n",
        "\n",
        "\n",
        "def remove_duplicates(df, subset_columns):\n",
        "\n",
        "    before_count = df.shape[0]\n",
        "    print(f\"Before removing duplicates: {before_count} rows\")\n",
        "\n",
        "    df_cleaned = df.drop_duplicates(subset=subset_columns)\n",
        "\n",
        "    after_count = df_cleaned.shape[0]\n",
        "    print(f\"After removing duplicates: {after_count} rows\")\n",
        "\n",
        "    removed_count = before_count - after_count\n",
        "    print(f\"Number of duplicates removed: {removed_count} rows\")\n",
        "\n",
        "    return df_cleaned\n",
        "\n",
        "\n",
        "def filter_by_duration(df):\n",
        "\n",
        "    if 'Duration' in df.columns:\n",
        "\n",
        "        duration_numeric = pd.to_numeric(df['Duration'], errors='coerce')\n",
        "        duration_numeric = duration_numeric.apply(lambda x: x / 1000 if x >= 1000 else x)\n",
        "        mask = (duration_numeric >= 30) | duration_numeric.isna()\n",
        "        filtered_df = df[mask]\n",
        "        removed_rows = len(df) - len(filtered_df)\n",
        "        print(f\"Number of rows filtered out by duration: {removed_rows}\")\n",
        "        return filtered_df\n",
        "\n",
        "    else:\n",
        "        print(\"The 'Duration' column is not present in the DataFrame.\")\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "def seconds_to_hms(seconds):\n",
        "    minutes = int(seconds // 60)\n",
        "    seconds = int(round(seconds % 60))\n",
        "    return f\"{minutes}m {seconds:02}s\"\n",
        "\n",
        "def duration_stats(df, column_name='Duration'):\n",
        "\n",
        "    if column_name in df.columns:\n",
        "        df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n",
        "        df[column_name] = df[column_name].apply(lambda x: x / 1000 if x >= 1000 else x)\n",
        "        df_filtered = df[df[column_name].notna()]\n",
        "\n",
        "        if not df_filtered.empty:\n",
        "            min_duration = df_filtered[column_name].min()\n",
        "            max_duration = df_filtered[column_name].max()\n",
        "            mean_duration = df_filtered[column_name].mean()\n",
        "\n",
        "            min_duration_hms = seconds_to_hms(min_duration)\n",
        "            max_duration_hms = seconds_to_hms(max_duration)\n",
        "            mean_duration_hms = seconds_to_hms(mean_duration)\n",
        "\n",
        "            return {\n",
        "                \"Shortest track duration\": min_duration_hms,\n",
        "                \"Longest track duration\": max_duration_hms,\n",
        "                \"Average track duration\": mean_duration_hms\n",
        "            }\n",
        "        else:\n",
        "            print(\"No valid duration data available after filtering 'N/A' or invalid values.\")\n",
        "            return None\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYt3e2Mrej3L"
      },
      "source": [
        "# **LastFM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPxi0Ga4SyZo"
      },
      "outputs": [],
      "source": [
        "last_fm_api_key = config['last_fm_api_key']\n",
        "user_name = 'slazur83'\n",
        "\n",
        "base_url = \"http://ws.audioscrobbler.com/2.0/\"\n",
        "params = {\n",
        "    'method': 'user.getrecenttracks',\n",
        "    'user': user_name,\n",
        "    'api_key': last_fm_api_key,\n",
        "    'format': 'json',\n",
        "    'limit': 200,\n",
        "    'page': 1\n",
        "}\n",
        "\n",
        "base_filename = \"lastfm_tracks.csv\"\n",
        "directory = '.'\n",
        "drive_folder = '/content/drive/MyDrive/Dane z aplikacji/LastFM/'\n",
        "\n",
        "def format_date(date_str):\n",
        "    if date_str == 'N/A':\n",
        "        return 'N/A'\n",
        "\n",
        "    try:\n",
        "        return datetime.strptime(date_str, '%d %b %Y, %H:%M:%S').strftime('%Y-%m-%d %H:%M')\n",
        "    except ValueError:\n",
        "        try:\n",
        "            return datetime.strptime(date_str, '%d %b %Y, %H:%M').strftime('%Y-%m-%d %H:%M')\n",
        "        except ValueError:\n",
        "            print(f\"Date format error for: {date_str}\")\n",
        "            return 'Invalid Date Format'\n",
        "\n",
        "def get_recent_tracks(params, max_retries=5):\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = requests.get(base_url, params=params)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except requests.exceptions.HTTPError as http_err:\n",
        "            if response.status_code >= 500:\n",
        "                retries += 1\n",
        "                wait_time = 2 ** retries\n",
        "                print(f\"Server error {response.status_code}. Retrying in {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"HTTP error occurred: {http_err}\")\n",
        "                raise\n",
        "        except requests.exceptions.RequestException as err:\n",
        "            print(f\"Error during requests: {err}\")\n",
        "            raise\n",
        "    print(f\"Failed after {max_retries} retries.\")\n",
        "    return None\n",
        "\n",
        "csv_file = base_filename\n",
        "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['artist', 'track', 'album', 'playback_date'])\n",
        "\n",
        "    while True:\n",
        "        data = get_recent_tracks(params)\n",
        "        if not data:\n",
        "            break\n",
        "\n",
        "        tracks = data.get('recenttracks', {}).get('track', [])\n",
        "        if not tracks:\n",
        "            break\n",
        "\n",
        "        for track in tracks:\n",
        "            artist = track.get('artist', {}).get('#text', 'N/A')\n",
        "            track_name = track.get('name', 'N/A')\n",
        "            album = track.get('album', {}).get('#text', 'N/A')\n",
        "            playback_date = format_date(track.get('date', {}).get('#text', 'N/A'))\n",
        "\n",
        "            writer.writerow([artist, track_name, album, playback_date])\n",
        "\n",
        "        params['page'] += 1\n",
        "\n",
        "print(f\"Data written to {csv_file}\")\n",
        "\n",
        "shutil.copy(csv_file, drive_folder)\n",
        "print(f\"The file has been saved in {drive_folder}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_folder = '/content/drive/MyDrive/Dane z aplikacji/LastFM/'\n",
        "base_filename = \"lastfm_tracks.csv\"\n",
        "csv_file = base_filename\n",
        "\n",
        "def convert_to_datetime(date_str):\n",
        "    try:\n",
        "        return pd.to_datetime(date_str, format='%Y-%m-%d %H:%M', errors='coerce')\n",
        "    except (ValueError, TypeError) as e:\n",
        "        print(f\"Error converting {date_str}: {e}\")\n",
        "        return pd.NaT\n",
        "\n",
        "df_lastfm = pd.read_csv(drive_folder + csv_file, header=0)\n",
        "df_lastfm.columns = ['Artist', 'Track', 'Album', 'Date']\n",
        "\n",
        "df_lastfm['Date'] = df_lastfm['Date'].apply(convert_to_datetime)\n",
        "df_lastfm['Date'] = df_lastfm['Date'].dt.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "df_lastfm['Source'] = 'LastFM'\n",
        "df_lastfm['Account'] = 'slazur83'\n",
        "\n",
        "df_lastfm[['Artist', 'Track']] = df_lastfm.apply(\n",
        "    lambda row: standardize_artist_and_track(row['Artist'], row['Track']), axis=1, result_type=\"expand\")\n",
        "\n",
        "df_lastfm = remove_duplicates(df_lastfm, ['Date', 'Artist', 'Track'])\n",
        "\n",
        "df_lastfm = filter_by_duration(df_lastfm)\n",
        "\n",
        "df_lastfm = df_lastfm.copy().assign(**{'Sub-source': 'N/A'})\n",
        "\n",
        "stats = duration_stats(df_lastfm)\n",
        "if stats:\n",
        "    print(stats)"
      ],
      "metadata": {
        "id": "qW9455axpDfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN45KgJ9Dc-w"
      },
      "source": [
        "# **YouTube Music**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_paths = {\n",
        "    'riwanna85': '/content/drive/MyDrive/Dane z aplikacji/Google/riwanna85/YouTube i YouTube Music/historia/',\n",
        "    'slazur83': '/content/drive/MyDrive/Dane z aplikacji/Google/slazur83/YouTube i YouTube Music/historia/'\n",
        "}\n",
        "file_name = 'historia oglądania.json'\n",
        "\n",
        "def extract_artist(subtitles):\n",
        "    return subtitles[0].get('name', '').split(' - ')[0] if isinstance(subtitles, list) and subtitles else ''\n",
        "\n",
        "def extract_song_title(title):\n",
        "    return title.replace(\"Obejrzano: \", \"\") if title.startswith(\"Obejrzano: \") else title\n",
        "\n",
        "def load_and_process_data(folder_path, account_name):\n",
        "    source_file = os.path.join(folder_path, file_name)\n",
        "    if not os.path.isfile(source_file):\n",
        "        print(f\"Brak pliku historii: {source_file}\")\n",
        "        return pd.DataFrame(columns=['Artist', 'Track', 'Date', 'Duration', 'Source', 'Account'])\n",
        "\n",
        "    df = pd.read_json(source_file, encoding='utf-8')\n",
        "    df = df[df['header'] == 'YouTube Music'].copy()\n",
        "    df['Artist'] = df['subtitles'].apply(extract_artist)\n",
        "    df['Track'] = df['title'].apply(extract_song_title)\n",
        "    df['Date'] = pd.to_datetime(df['time'], format='ISO8601').dt.strftime('%Y-%m-%d %H:%M')\n",
        "    df['Source'], df['Account'], df['Duration'] = 'YouTube Music', account_name, 'N/A'\n",
        "    return df[['Artist', 'Track', 'Date', 'Duration', 'Source', 'Account']]\n",
        "\n",
        "df_ytmusic = pd.concat(\n",
        "    [load_and_process_data(path, account) for account, path in folder_paths.items()],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "df_ytmusic[['Artist', 'Track']] = df_ytmusic.apply(\n",
        "    lambda row: standardize_artist_and_track(row['Artist'], row['Track']), axis=1, result_type=\"expand\"\n",
        ")\n",
        "\n",
        "df_ytmusic = remove_duplicates(df_ytmusic, ['Date', 'Artist', 'Track'])\n",
        "\n",
        "df_ytmusic = filter_by_duration(df_ytmusic)\n",
        "\n",
        "df_ytmusic = df_ytmusic.copy().assign(**{'Sub-source': 'N/A'})\n",
        "\n",
        "stats = duration_stats(df_ytmusic)\n",
        "if stats:\n",
        "    print(stats)"
      ],
      "metadata": {
        "id": "hDKuOh62ITsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_account_data(account_data):\n",
        "    return account_data.groupby('Account').agg(\n",
        "        start_date=('Date', 'min'), end_date=('Date', 'max'), row_count=('Account', 'size')\n",
        "    ).reset_index()\n",
        "\n",
        "final_summary = summarize_account_data(df_ytmusic)\n",
        "\n",
        "print(\"\\nFinal Summary of Accounts\")\n",
        "print(tabulate(final_summary, headers='keys', tablefmt='pretty'))\n",
        "\n",
        "overall_start_date, overall_end_date, overall_row_count = (\n",
        "    df_ytmusic['Date'].min(), df_ytmusic['Date'].max(), df_ytmusic.shape[0]\n",
        ") if not df_ytmusic.empty else (None, None, 0)\n",
        "\n",
        "print(f\"\\nOverall Summary:\\nDate range: from {overall_start_date} to {overall_end_date}\\nTotal Row count: {overall_row_count}\\n\")"
      ],
      "metadata": {
        "id": "kKxXVdAmLik4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqLYlxpjTaKw"
      },
      "source": [
        "# **Spotify**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QPutDy0IGH6"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def load_spotify_data(base_path, account_name):\n",
        "    mydata_folders = glob.glob(os.path.join(base_path, \"MyData*\"))\n",
        "    df_list = []\n",
        "\n",
        "    for folder in mydata_folders:\n",
        "        takeout_name = os.path.basename(folder)\n",
        "\n",
        "        all_files = glob.glob(os.path.join(folder, \"StreamingHistory*.json\")) + \\\n",
        "                    glob.glob(os.path.join(folder, \"Streaming_History_Audio_*.json\")) + \\\n",
        "                    glob.glob(os.path.join(folder, \"Streaming_History_Video_*.json\"))\n",
        "\n",
        "        music_files = {file for file in all_files if 'podcast' not in os.path.basename(file).lower() and 'video' not in os.path.basename(file).lower()}\n",
        "\n",
        "        logging.info(f\"\\nFiles found in {takeout_name} for account {account_name}:\")\n",
        "        for file in music_files:\n",
        "            logging.info(f\" - {file}\")\n",
        "\n",
        "            try:\n",
        "                with open(file, 'r', encoding='utf-8') as f:\n",
        "                    if f.read().strip():\n",
        "                        df = pd.read_json(file)\n",
        "\n",
        "                        if 'endTime' in df.columns:\n",
        "                            df = df.rename(columns={'endTime': 'Date', 'artistName': 'Artist', 'trackName': 'Track', 'msPlayed': 'Duration'})\n",
        "                        elif 'ts' in df.columns and 'master_metadata_track_name' in df.columns:\n",
        "                            df = df.rename(columns={'ts': 'Date', 'master_metadata_album_artist_name': 'Artist', 'master_metadata_track_name': 'Track', 'ms_played': 'Duration'})\n",
        "                            df['Date'] = pd.to_datetime(df['Date'], errors='coerce', utc=True)\n",
        "                            df['Date'] = df['Date'].dt.floor('min')\n",
        "\n",
        "                        df['Account'] = account_name\n",
        "                        df['Takeout'] = takeout_name\n",
        "                        df_list.append(df[['Artist', 'Track', 'Date', 'Duration', 'Account', 'Takeout']])\n",
        "                    else:\n",
        "                        logging.warning(f\"Skipping empty file: {file}\")\n",
        "            except ValueError as e:\n",
        "                logging.error(f\"Error reading {file}: {e} - Skipping this file.\")\n",
        "\n",
        "    if df_list:\n",
        "        combined_df = pd.concat(df_list, ignore_index=True)\n",
        "    else:\n",
        "        combined_df = pd.DataFrame()\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "df1 = load_spotify_data('/content/drive/MyDrive/Dane z aplikacji/Spotify/slazur83@gmail.com/', 'slazur83')\n",
        "df2 = load_spotify_data('/content/drive/MyDrive/Dane z aplikacji/Spotify/zethar182@gmail.com/', 'zethar182')\n",
        "\n",
        "df_spotify = pd.concat([df1, df2], ignore_index=True)\n",
        "df_spotify['Source'] = 'Spotify'\n",
        "\n",
        "df_spotify['Date'] = pd.to_datetime(df_spotify['Date'], errors='coerce', utc=True)\n",
        "df_spotify = df_spotify.dropna(subset=['Date'])\n",
        "\n",
        "df_spotify['Date'] = df_spotify['Date'].dt.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "df_spotify[['Artist', 'Track']] = df_spotify.apply(\n",
        "    lambda row: standardize_artist_and_track(row['Artist'], row['Track']), axis=1, result_type=\"expand\"\n",
        ")\n",
        "\n",
        "df_spotify = remove_duplicates(df_spotify, ['Date', 'Artist', 'Track'])\n",
        "\n",
        "df_spotify = filter_by_duration(df_spotify)\n",
        "\n",
        "df_spotify = df_spotify.copy().assign(**{'Sub-source': 'N/A'})\n",
        "\n",
        "stats = duration_stats(df_spotify)\n",
        "if stats:\n",
        "    print(stats)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_account_data(account_data):\n",
        "    takeout_summary = account_data.groupby('Takeout').agg(\n",
        "        start_date=('Date', 'min'),\n",
        "        end_date=('Date', 'max'),\n",
        "        row_count=('Takeout', 'count')\n",
        "    ).reset_index()\n",
        "\n",
        "    takeout_summary['Account'] = account_data['Account'].iloc[0]\n",
        "    return takeout_summary[['Account', 'Takeout', 'start_date', 'end_date', 'row_count']]\n",
        "\n",
        "final_summary = pd.concat([\n",
        "    summarize_account_data(df_spotify[df_spotify['Account'] == 'zethar182']),\n",
        "    summarize_account_data(df_spotify[df_spotify['Account'] == 'slazur83'])\n",
        "], ignore_index=True)\n",
        "\n",
        "print(\"\\nFinal Summary of Accounts\")\n",
        "print(tabulate(final_summary, headers='keys', tablefmt='pretty'))\n",
        "\n",
        "overall_start_date = df_spotify['Date'].min() if not df_spotify.empty else None\n",
        "overall_end_date = df_spotify['Date'].max() if not df_spotify.empty else None\n",
        "overall_row_count = df_spotify.shape[0] if not df_spotify.empty else 0\n",
        "\n",
        "print(f\"\\nOverall Summary:\\nDate range: from {overall_start_date} to {overall_end_date}\\nTotal Row count: {overall_row_count}\\n\")"
      ],
      "metadata": {
        "id": "EvMtOqkuL3-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8veMxiBg5QJ"
      },
      "source": [
        "# **Deezer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xH9JpEB3SVt"
      },
      "outputs": [],
      "source": [
        "deezer_file = '/content/drive/MyDrive/Dane z aplikacji/Deezer/4519420622.xlsx'\n",
        "\n",
        "df_deezer = pd.read_excel(deezer_file, sheet_name=\"10_listeningHistory\")\n",
        "\n",
        "df_deezer = df_deezer.rename(columns={\n",
        "    'Song Title': 'Track',\n",
        "    'Album Title': 'Album',\n",
        "    'Listening Time': 'Duration',\n",
        "    'Platform Name': 'Platform'\n",
        "})\n",
        "\n",
        "df_deezer = df_deezer.drop(columns=['ISRC'], errors='ignore')\n",
        "\n",
        "df_deezer['Source'] = 'Deezer'\n",
        "df_deezer['Account'] = 'slazur83'\n",
        "\n",
        "df_deezer['Date'] = pd.to_datetime(df_deezer['Date'], errors='coerce')\n",
        "df_deezer['Date'] = df_deezer['Date'].dt.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "df_deezer[['Artist', 'Track']] = df_deezer.apply(\n",
        "    lambda row: standardize_artist_and_track(row['Artist'], row['Track']), axis=1, result_type=\"expand\"\n",
        ")\n",
        "\n",
        "df_deezer = df_deezer.dropna(subset=['Date'])\n",
        "\n",
        "df_deezer = remove_duplicates(df_deezer, ['Date', 'Artist', 'Track'])\n",
        "\n",
        "df_deezer = filter_by_duration(df_deezer)\n",
        "\n",
        "df_deezer = df_deezer.copy().assign(**{'Sub-source': 'N/A'})\n",
        "\n",
        "stats = duration_stats(df_deezer)\n",
        "if stats:\n",
        "    print(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEZDcOfTLZD7"
      },
      "source": [
        "**Final DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged = pd.concat([df_spotify, df_ytmusic, df_lastfm, df_deezer], ignore_index=True)\n",
        "merged['Date'] = pd.to_datetime(merged['Date'])\n",
        "\n",
        "nulls = merged['Date'].isna().sum()\n",
        "if nulls > 0:\n",
        "    if nulls < 15:\n",
        "        merged.dropna(subset=['Date'], inplace=True)\n",
        "        print(f'Dropped {nulls} rows with missing Date values.')\n",
        "    else:\n",
        "        raise ValueError(f'There are {nulls} null values in the Date column that need attention.')\n",
        "else:\n",
        "    print('No null values found in the Date column.\\n')\n",
        "\n",
        "columns_order = ['Date', 'Artist', 'Track', 'Album', 'Duration', 'Source', 'Sub-source', 'Account', 'Platform', 'Platform Model', 'IP Address']\n",
        "merged = merged.reindex(columns=columns_order).copy()\n",
        "merged['Date'] = pd.to_datetime(merged['Date'])\n",
        "merged = merged.sort_values(by='Date', inplace=False)\n",
        "\n",
        "all_merged = merged.copy()\n",
        "all_merged[\"Source\"] = 'All Merged'\n",
        "all_merged['Sub-source'] = merged['Source']\n",
        "all_merged_no_duplicates = all_merged.drop_duplicates(subset=['Date', 'Artist', 'Track'], keep='first')\n",
        "final_df = pd.concat([merged, all_merged_no_duplicates], ignore_index=True)"
      ],
      "metadata": {
        "id": "u3w_ZIn_KPpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import Timedelta\n",
        "\n",
        "lastfm_df = final_df[final_df['Sub-source'] == 'LastFM'].copy()\n",
        "other_df = final_df[(final_df['Sub-source'] != 'LastFM') & (final_df['Source'] == 'All Merged')].copy()\n",
        "\n",
        "for minutes in range(1, 10):\n",
        "\n",
        "    lastfm_temp_df = lastfm_df.copy()\n",
        "    lastfm_temp_df['Date'] = lastfm_temp_df['Date'] + Timedelta(minutes=minutes)\n",
        "    temp_combined_df = pd.concat([other_df, lastfm_temp_df])\n",
        "    temp_combined_df = temp_combined_df.drop_duplicates(subset=['Date', 'Artist', 'Track'], keep=False)\n",
        "    lastfm_df = lastfm_df[lastfm_df.index.isin(temp_combined_df.index)]\n",
        "\n",
        "checked_df = pd.concat([other_df, lastfm_df]).drop_duplicates(subset=['Date', 'Artist', 'Track'])\n",
        "final_df = pd.concat([merged, checked_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "d-UBw4i0WYEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for source in final_df['Source'].unique():\n",
        "    source_data = final_df[final_df['Source'] == source]\n",
        "\n",
        "    total_rows = source_data.shape[0]\n",
        "    start_date = source_data['Date'].min().strftime('%Y-%m-%d %H:%M') if total_rows > 0 else \"N/A\"\n",
        "    end_date = source_data['Date'].max().strftime('%Y-%m-%d %H:%M') if total_rows > 0 else \"N/A\"\n",
        "    distinct_artists = source_data['Artist'].nunique()\n",
        "    distinct_tracks = source_data['Track'].nunique()\n",
        "\n",
        "    print(f\"Source: {source}\")\n",
        "    print(f\"  Total rows: {total_rows}\")\n",
        "    print(f\"  Start date: {start_date}\")\n",
        "    print(f\"  End date: {end_date}\")\n",
        "    print(f\"  Distinct artists: {distinct_artists}\")\n",
        "    print(f\"  Distinct tracks: {distinct_tracks}\\n\")"
      ],
      "metadata": {
        "id": "2T6FmnGYGW7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path1 = '/content/drive/MyDrive/Skrypty/Tableau/Outputs/music_tracks.csv'\n",
        "output_path2 = '/content/drive/MyDrive/Skrypty/Tableau/Outputs/music_tracks.xlsx'\n",
        "\n",
        "final_df.to_csv(output_path1, index=False)\n",
        "print(f'Data successfully exported to {output_path1}')\n",
        "\n",
        "final_df.to_excel(output_path2, index=False)\n",
        "print(f'Data successfully exported to {output_path2}')"
      ],
      "metadata": {
        "id": "LhcpMz96nXDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NGi0yoJ2G"
      },
      "source": [
        "**Matching entries in LastFM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuCDlP7Ma1i0"
      },
      "outputs": [],
      "source": [
        "merged_data = final_df.copy()\n",
        "\n",
        "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
        "merged_data['Duration'] = pd.to_numeric(merged_data['Duration'], errors='coerce')\n",
        "\n",
        "filtered_sources = merged_data.query(\"Duration.isna() or Duration >= 30\")\n",
        "\n",
        "lastfm_data = merged_data.query(\"Source == 'LastFM'\").copy()\n",
        "lastfm_data['key'] = lastfm_data[['Artist', 'Track']].apply(tuple, axis=1)\n",
        "\n",
        "def match_within_period(row, lastfm_data):\n",
        "    time_window = pd.Timedelta(minutes=5)\n",
        "    matching_rows = lastfm_data[\n",
        "        (lastfm_data['key'] == row['key']) &\n",
        "        (abs(lastfm_data['Date'] - row['Date']) <= time_window)\n",
        "    ]\n",
        "    return not matching_rows.empty\n",
        "\n",
        "report = []\n",
        "\n",
        "for source in merged_data['Source'].unique():\n",
        "    if source in ('LastFM', 'All Merged'):\n",
        "        continue\n",
        "\n",
        "    source_data = merged_data.query(\"Source == @source\")\n",
        "\n",
        "    start_date = lastfm_data['Date'].min()\n",
        "    end_date = source_data['Date'].max()\n",
        "\n",
        "    filtered_source_data = source_data.query(\"@start_date <= Date <= @end_date\").copy()\n",
        "    filtered_source_data['key'] = filtered_source_data[['Artist', 'Track']].apply(tuple, axis=1)\n",
        "\n",
        "    filtered_source_data['Exists_in_LastFM'] = filtered_source_data.apply(\n",
        "        match_within_period, lastfm_data=lastfm_data, axis=1\n",
        "    )\n",
        "\n",
        "    matching_count = filtered_source_data['Exists_in_LastFM'].sum()\n",
        "    total_source_count = len(filtered_source_data)\n",
        "    matching_percentage = (matching_count / total_source_count * 100) if total_source_count > 0 else 0\n",
        "\n",
        "    report.append({\n",
        "        'Source': source,\n",
        "        'Start Date': start_date.strftime(\"%Y-%m-%d\"),\n",
        "        'End Date': end_date.strftime(\"%Y-%m-%d\"),\n",
        "        'Total Entries': total_source_count,\n",
        "        'Matching Entries': matching_count,\n",
        "        'Matching Percentage': f\"{matching_percentage:.2f}%\"\n",
        "    })\n",
        "\n",
        "for entry in report:\n",
        "    print(f\"Source: {entry['Source']}\")\n",
        "    print(f\"  Start Date: {entry['Start Date']}\")\n",
        "    print(f\"  End Date: {entry['End Date']}\")\n",
        "    print(f\"  Total Entries: {entry['Total Entries']}\")\n",
        "    print(f\"  Matching Entries: {entry['Matching Entries']}\")\n",
        "    print(f\"  Percentage of Matching Entries in LastFM: {entry['Matching Percentage']}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = final_df[(final_df['Source'] == 'All Merged') &\n",
        "                       (final_df['Date'].dt.month == 9) &\n",
        "                       (final_df['Date'].dt.year == 2024) &\n",
        "                       (final_df['Date'].dt.day == 14)]\n",
        "\n",
        "filtered_df_sorted = filtered_df.sort_values(by='Date')\n",
        "display(filtered_df)\n"
      ],
      "metadata": {
        "id": "KB6uYaJP3AGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaAQZkYfcotm"
      },
      "outputs": [],
      "source": [
        "unique_artists = final_df[\"Artist\"].dropna().unique()\n",
        "unique_artists = [str(artist) for artist in unique_artists]\n",
        "\n",
        "unique_tracks = final_df[\"Track\"].dropna().unique()\n",
        "unique_tracks = [str(track) for track in unique_tracks]\n",
        "\n",
        "sorted_artists = sorted(unique_artists)\n",
        "sorted_tracks = sorted(unique_tracks)\n",
        "\n",
        "artist_track_df = final_df[[\"Artist\", \"Track\"]].dropna().drop_duplicates()\n",
        "artist_track_df = artist_track_df.sort_values(by=[\"Artist\", \"Track\"])\n",
        "\n",
        "artist_track_counts = final_df.groupby([\"Artist\", \"Track\"]).size().reset_index(name=\"Count\")\n",
        "artist_track_counts = artist_track_counts.sort_values(by=\"Count\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for artist in sorted_artists:\n",
        "  print(artist)"
      ],
      "metadata": {
        "id": "Mok88KTyLUam"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Nxr7fSxPw5_9luzBYxemvGg8v40m-82q",
      "authorship_tag": "ABX9TyO6oLIW5F1oxZFWvzjwLaMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}